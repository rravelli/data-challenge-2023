{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost - Remplacement des Nans\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On choisit XGBoost car on a déja obtenu de très bons résultats avec.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Préparation des données V1 - 2023/11/19 - NaN en zéros\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stratégie :  \n",
    "On remplace les heures par des floats, les identifiants de station par des entiers et on supprime la colonne 'date'.  \n",
    "(La suppression de la colonne 'way' a été oubliée)\n",
    "On a fait une division : 90% du dataset pour le train, 10% pour le test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Import des données\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../../../data\"\n",
    "x_data = pd.read_csv(path + \"/Xtrain_hgcGIrA.csv\", sep=\",\")  # features\n",
    "y_data = pd.read_csv(\n",
    "    path + \"/Ytrain_yL5OjS4.csv\", sep=\",\", usecols=[1]\n",
    ")  # occupancy rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mise en forme des données\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = x_data.drop(\"date\", axis=1)  # on supprime la colonne date\n",
    "x_data = x_data.drop(\"way\", axis=1) #  on supprime la colonne way\n",
    "x_data[\"hour\"] = x_data[\"hour\"].apply(\n",
    "    lambda x: 0 if type(x) == float else int(x[:2])\n",
    ") # on remplace les Nan de hour par des 0 et les heures par des entiers\n",
    "\n",
    "#on remplace les Nan des pxqx par 0\n",
    "x_data[[\"p1q0\", \"p2q0\", \"p3q0\", \"p0q1\", \"p0q2\", \"p0q3\"]] = x_data[[\"p1q0\", \"p2q0\", \"p3q0\", \"p0q1\", \"p0q2\", \"p0q3\"]].fillna(0)\n",
    "\n",
    "# on tranforme les identifiants de gare en entiers\n",
    "x_data[\"station\"] = x_data[\"station\"].astype(\"category\")\n",
    "cat_columns = x_data.select_dtypes([\"category\"]).columns\n",
    "x_data[cat_columns] = x_data[cat_columns].apply(lambda x: x.cat.codes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Création d'un dataset de test et de validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    x_data.values, y_data.values, train_size=0.8\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoostREGRESSOR - 2023/11/20 - Préparation des données V1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On utilise le regresseur et pas le classifieur car on ne cherche pas la classe de p0q0 mais sa valeur précise.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Import de XGBRegresseur\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Test sans jouer sur les paramètres\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9849680434807259"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGBR = XGBRegressor()\n",
    "XGBR.fit(X_train, y_train)\n",
    "XGBR.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le score est légèrement supérieur à celui qu'on avait quand on conservait les NaN. En jouant sur les paramètres comme expliqué ci-dessous, on va essayer de l'augmenter.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Choix de n_estimators\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/mcoutier/Centrale/STASC/data-challenge-2023/3_best_models_improvement/3_1_data_imputation/xgboost/train_xgboost.ipynb Cell 20\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/mcoutier/Centrale/STASC/data-challenge-2023/3_best_models_improvement/3_1_data_imputation/xgboost/train_xgboost.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m tuned_parameters \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mn_estimators\u001b[39m\u001b[39m\"\u001b[39m: n_estimators}\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/mcoutier/Centrale/STASC/data-challenge-2023/3_best_models_improvement/3_1_data_imputation/xgboost/train_xgboost.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m XGBR_params \u001b[39m=\u001b[39m GridSearchCV(\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/mcoutier/Centrale/STASC/data-challenge-2023/3_best_models_improvement/3_1_data_imputation/xgboost/train_xgboost.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m     XGBRegressor(learning_rate\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m), tuned_parameters, cv\u001b[39m=\u001b[39mmy_kfold, n_jobs\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/mcoutier/Centrale/STASC/data-challenge-2023/3_best_models_improvement/3_1_data_imputation/xgboost/train_xgboost.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m )\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/mcoutier/Centrale/STASC/data-challenge-2023/3_best_models_improvement/3_1_data_imputation/xgboost/train_xgboost.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m XGBR_params\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/mcoutier/Centrale/STASC/data-challenge-2023/3_best_models_improvement/3_1_data_imputation/xgboost/train_xgboost.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mprint\u001b[39m(XGBR_params\u001b[39m.\u001b[39mscore(X_test, y_test), XGBR_params\u001b[39m.\u001b[39mbest_params_)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/mcoutier/Centrale/STASC/data-challenge-2023/3_best_models_improvement/3_1_data_imputation/xgboost/train_xgboost.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mstr\u001b[39m(time() \u001b[39m-\u001b[39m start) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m sec\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/STASC/lib/python3.10/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/STASC/lib/python3.10/site-packages/sklearn/model_selection/_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    892\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[1;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    894\u001b[0m     )\n\u001b[1;32m    896\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[0;32m--> 898\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[1;32m    900\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    901\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    902\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/STASC/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1419\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1417\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1418\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1419\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[0;32m~/miniconda3/envs/STASC/lib/python3.10/site-packages/sklearn/model_selection/_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    838\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[1;32m    839\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    840\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[1;32m    842\u001b[0m         )\n\u001b[1;32m    843\u001b[0m     )\n\u001b[0;32m--> 845\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    846\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    847\u001b[0m         clone(base_estimator),\n\u001b[1;32m    848\u001b[0m         X,\n\u001b[1;32m    849\u001b[0m         y,\n\u001b[1;32m    850\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[1;32m    851\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[1;32m    852\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[1;32m    853\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[1;32m    854\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[1;32m    855\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[1;32m    856\u001b[0m     )\n\u001b[1;32m    857\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[1;32m    858\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[1;32m    859\u001b[0m     )\n\u001b[1;32m    860\u001b[0m )\n\u001b[1;32m    862\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    863\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    864\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    865\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    866\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    867\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/STASC/lib/python3.10/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[0;32m~/miniconda3/envs/STASC/lib/python3.10/site-packages/joblib/parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1097\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1098\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n\u001b[1;32m   1099\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[0;32m~/miniconda3/envs/STASC/lib/python3.10/site-packages/joblib/parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    974\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m--> 975\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout))\n\u001b[1;32m    976\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    977\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "File \u001b[0;32m~/miniconda3/envs/STASC/lib/python3.10/site-packages/joblib/_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[1;32m    565\u001b[0m \u001b[39mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[1;32m    566\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 567\u001b[0m     \u001b[39mreturn\u001b[39;00m future\u001b[39m.\u001b[39;49mresult(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m    568\u001b[0m \u001b[39mexcept\u001b[39;00m CfTimeoutError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    569\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/STASC/lib/python3.10/concurrent/futures/_base.py:453\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[1;32m    451\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_result()\n\u001b[0;32m--> 453\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_condition\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    456\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m~/miniconda3/envs/STASC/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[1;32m    321\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from time import time\n",
    "\n",
    "start = time()\n",
    "\n",
    "my_kfold = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "n_estimators = np.arange(800, 1500, 20)\n",
    "\n",
    "tuned_parameters = {\"n_estimators\": n_estimators}\n",
    "\n",
    "XGBR_params = GridSearchCV(\n",
    "    XGBRegressor(learning_rate=0.1), tuned_parameters, cv=my_kfold, n_jobs=-1\n",
    ")\n",
    "\n",
    "XGBR_params.fit(X_train, y_train)\n",
    "print(XGBR_params.score(X_test, y_test), XGBR_params.best_params_)\n",
    "print(str(time() - start) + \" sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Premier test avec\n",
    "\n",
    "- n_estimators = [100, 300, 500, 1000, 2000]\n",
    "\n",
    "On obtient :\n",
    "\n",
    "0.9876833947427778 {'n_estimators': 1000}    \n",
    "37.39019751548767 sec\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deuxième test avec :\n",
    "\n",
    "- n_estimators = np.arange(800, 2000, 60)\n",
    "\n",
    "On obtient :\n",
    "\n",
    "0.9876712793712039 {'n_estimators': 860}   \n",
    "158.15269088745117 sec\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Troisième test avec :\n",
    "\n",
    "- n_estimators = np.arange(800, 1500, 20)\n",
    "\n",
    "On obtient :\n",
    "\n",
    "0.9876745050395136 {'n_estimators': 840}    \n",
    "236.91013956069946 sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On choisit n_estimators = 840 pour un learning rate de 0.1. On reverra cet équilibre à la fin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- choix de max_depth et min_child_weight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9876745050395136 {'max_depth': 6, 'min_child_weight': 1}\n",
      "1005.280415058136 sec\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "\n",
    "my_kfold = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "max_depth = np.arange(1,15,1)\n",
    "min_child_weight = np.arange(1,15,1)\n",
    "\n",
    "tuned_parameters = {\n",
    "    \"max_depth\": max_depth,\n",
    "    \"min_child_weight\": min_child_weight,\n",
    "}\n",
    "\n",
    "XGBR_params = GridSearchCV(\n",
    "    XGBRegressor(n_estimators=840, learning_rate=0.1),\n",
    "    tuned_parameters,\n",
    "    cv=my_kfold,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "XGBR_params.fit(X_train, y_train)\n",
    "print(XGBR_params.score(X_test, y_test), XGBR_params.best_params_)\n",
    "print(str(time() - start) + \" sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Premier test avec\n",
    "\n",
    "- max_depth = np.arange(1,15,1)\n",
    "- min_child_weight = np.arange(1,15,1)\n",
    "\n",
    "On obtient :\n",
    "\n",
    "0.9876745050395136 {'max_depth': 6, 'min_child_weight': 1}    \n",
    "1005.280415058136 sec\n",
    "\n",
    "Le score n'a pas changé.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- choix de gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9876429928422733 {'gamma': 1e-05}\n",
      "65.31180882453918 sec\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "\n",
    "my_kfold = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "gamma = np.linspace(0.00001,0.008,15)\n",
    "\n",
    "tuned_parameters = {\"gamma\": gamma}\n",
    "\n",
    "XGBR_params = GridSearchCV(\n",
    "    XGBRegressor(\n",
    "        n_estimators=840, learning_rate=0.1, max_depth=6, min_child_weight=1\n",
    "    ),\n",
    "    tuned_parameters,\n",
    "    cv=my_kfold,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "XGBR_params.fit(X_train, y_train)\n",
    "print(XGBR_params.score(X_test, y_test), XGBR_params.best_params_)\n",
    "print(str(time() - start) + \" sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Premier test avec\n",
    "\n",
    "- gamma = [0.1,0.5,1,5,10,30,50,100]\n",
    "\n",
    "On obtient :\n",
    "\n",
    "0.9751867200255847 {'gamma': 0.1}    \n",
    "45.6101713180542 sec\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deuxième test avec\n",
    "\n",
    "- gamma = np.linspace(0.01,1.1,15)\n",
    "\n",
    "On obtient :\n",
    "\n",
    "0.9830294800009547 {'gamma': 0.01}    \n",
    "165.9118287563324 sec\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Troisième test avec\n",
    "\n",
    "- gamma = np.linspace(0.001,0.8,15)\n",
    "\n",
    "On obtient :\n",
    "\n",
    "0.9872501162550665 {'gamma': 0.001}    \n",
    "76.28652811050415 sec\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quatrième test avec\n",
    "\n",
    "- gamma = np.linspace(0.0001,0.08,15)\n",
    "\n",
    "On obtient :\n",
    "\n",
    "0.9878007798386781 {'gamma': 0.0001}\n",
    "71.47756004333496 sec\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cinquième test avec\n",
    "\n",
    "- gamma = np.linspace(0.00001,0.008,15)\n",
    "\n",
    "On obtient :\n",
    "\n",
    "0.9876429928422733 {'gamma': 1e-05}\n",
    "65.31180882453918 sec\n",
    "\n",
    "Le score a baissé, on choisira donc plutôt 0.0001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- choix de subsample et colsample_bytree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9878386938908292 {'subsample': 0.8210526315789474}\n",
      "98.14557838439941 sec\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "\n",
    "my_kfold = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "subsample = np.linspace(0.8,0.9,20)\n",
    "\n",
    "tuned_parameters = {\"subsample\": subsample}\n",
    "\n",
    "XGBR_params = GridSearchCV(\n",
    "    XGBRegressor(\n",
    "        n_estimators=840, learning_rate=0.1, max_depth=6, min_child_weight=1, gamma = 0.0001, colsample_bytree=1\n",
    "    ),\n",
    "    tuned_parameters,\n",
    "    cv=my_kfold,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "XGBR_params.fit(X_train, y_train)\n",
    "print(XGBR_params.score(X_test, y_test), XGBR_params.best_params_)\n",
    "print(str(time() - start) + \" sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Premier test avec\n",
    "\n",
    "- subsample = np.linspace(0.01,1,10)\n",
    "- colsample_bytree = np.linspace(0.01,1,10)\n",
    "\n",
    "On obtient :\n",
    "\n",
    "0.9877374857092629 {'colsample_bytree': 1.0, 'subsample': 0.78}    \n",
    "261.4477083683014 sec\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deuxième test avec\n",
    "\n",
    "- subsample = np.linspace(0.2,1,10)\n",
    "- colsample_bytree = np.linspace(0.1,1,10)\n",
    "\n",
    "On obtient :\n",
    "\n",
    "0.9878834537187015 {'colsample_bytree': 1.0, 'subsample': 0.8222222222222222}    \n",
    "301.5654721260071 sec\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Troisième test avec\n",
    "\n",
    "- subsample = np.linspace(0.5,1,10)\n",
    "- colsample_bytree = np.linspace(0.5,1,10)\n",
    "\n",
    "On obtient :\n",
    "\n",
    "0.9879713624111819 {'colsample_bytree': 1.0, 'subsample': 0.8888888888888888}    \n",
    "354.5157027244568 sec\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quatrième test avec\n",
    "\n",
    "- subsample = np.linspace(0.7,0.9,15)\n",
    "- colsample_bytree = np.linspace(0.8,1,15)\n",
    "\n",
    "On obtient :\n",
    "\n",
    "0.9880263402463824 {'colsample_bytree': 1.0, 'subsample': 0.8714285714285714}    \n",
    "936.7044553756714 sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On garde colsample_bytree = 1 et on essaye encore d'affiner subsample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cinquième test avec\n",
    "\n",
    "- subsample = np.linspace(0.8,0.9,20)\n",
    "\n",
    "On obtient :\n",
    "\n",
    "0.9878386938908292 {'subsample': 0.8210526315789474}    \n",
    "98.14557838439941 sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le score a diminué, on garde donc subsample = 0.8714285714285714"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- choix de reg_alpha et reg_lambda\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9880085018467166 {'reg_alpha': 0.034999999999999996, 'reg_lambda': 0.185}\n",
      "1070.048173904419 sec\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "\n",
    "my_kfold = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "reg_alpha = np.linspace(0.03,0.1,15)\n",
    "reg_lambda = np.linspace(0.01,0.5,15)\n",
    "\n",
    "tuned_parameters = {\"reg_alpha\": reg_alpha, \"reg_lambda\": reg_lambda}\n",
    "\n",
    "XGBR_params = GridSearchCV(\n",
    "    XGBRegressor(\n",
    "        n_estimators=840, learning_rate=0.1, max_depth=6, min_child_weight=1, gamma = 0.0001, colsample_bytree=1, subsample=0.8714285714285714 \n",
    "    ),\n",
    "    tuned_parameters,\n",
    "    cv=my_kfold,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "XGBR_params.fit(X_train, y_train)\n",
    "print(XGBR_params.score(X_test, y_test), XGBR_params.best_params_)\n",
    "print(str(time() - start) + \" sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Premier test avec\n",
    "\n",
    "- reg_alpha = [0.1,1,5,10,30,50,100]\n",
    "- reg_lambda = [0.1,1,5,10,30,50,100]\n",
    "\n",
    "On obtient :\n",
    "\n",
    "0.9878612773031041 {'reg_alpha': 0.1, 'reg_lambda': 0.1}\n",
    "119.39949417114258 sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deuxième test avec\n",
    "\n",
    "- reg_alpha = np.linspace(0.01,1,15)\n",
    "- reg_lambda = np.linspace(0.01,1,15)\n",
    "\n",
    "On obtient :\n",
    "\n",
    "0.9881048969848781 {'reg_alpha': 0.08071428571428571, 'reg_lambda': 0.15142857142857144}    \n",
    "1078.1922311782837 sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Troisième test avec\n",
    "\n",
    "- reg_alpha = np.linspace(0.03,0.1,15)\n",
    "- reg_lambda = np.linspace(0.01,0.5,15)\n",
    "\n",
    "On obtient :\n",
    "\n",
    "0.9880085018467166 {'reg_alpha': 0.034999999999999996, 'reg_lambda': 0.185}\n",
    "1070.048173904419 sec\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On conserve le deuxième test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Diminution du learning_rate et adaptation de n_estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ayant réalisé cette recherche de meilleur paramètres sur deux jours, le split du dataset en dataset d'apprentissage et dataset de test a changé et le score en a été modifié. Il est ici plus bas que précédemment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9868053089033629 {'n_estimators': 5750}\n",
      "323.44272923469543 sec\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "\n",
    "my_kfold = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "n_estimators = range(3500,6000,250)\n",
    "tuned_parameters = {\"n_estimators\": n_estimators}\n",
    "\n",
    "XGBR_params = GridSearchCV(\n",
    "    XGBRegressor( \n",
    "        learning_rate = 0.015,\n",
    "        max_depth=6, min_child_weight=1, \n",
    "        gamma = 0.0001, colsample_bytree=1, subsample=0.8714285714285714,\n",
    "        reg_alpha = 0.08071428571428571, reg_lambda= 0.15142857142857144\n",
    "    ),\n",
    "    tuned_parameters,\n",
    "    cv=my_kfold,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "XGBR_params.fit(X_train, y_train)\n",
    "print(XGBR_params.score(X_test, y_test), XGBR_params.best_params_)\n",
    "print(str(time() - start) + \" sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Premier test avec\n",
    "\n",
    "- n_estimators = [840,1000, 2000,3000]\n",
    "- learning_rate = [0.02,0.05,0.08,0.1]\n",
    "\n",
    "On obtient :\n",
    "\n",
    "0.9867792770846329 {'learning_rate': 0.02, 'n_estimators': 3000}\n",
    "194.5658085346222 sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deuxième test avec\n",
    "\n",
    "- n_estimators = [2000,3000, 4000, 5000]\n",
    "- learning_rate = [0.01,0.02,0.05,0.08]\n",
    "\n",
    "On obtient :\n",
    "\n",
    "0.9868273520059674 {'learning_rate': 0.02, 'n_estimators': 4000}\n",
    "360.37468552589417 sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Troisième test avec\n",
    "\n",
    "- n_estimators = [3000,3500, 4000, 4500, 5000]\n",
    "- learning_rate = [0.01,0.015,0.02,0.025, 0.03]\n",
    "\n",
    "On obtient :\n",
    "\n",
    "0.986800966197621 {'learning_rate': 0.015, 'n_estimators': 5000}\n",
    "595.9117505550385 sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quatrième test avec\n",
    "\n",
    "- n_estimators = range(3500,6000,250)\n",
    "\n",
    "On a fixé learning_rate à 0.015    \n",
    "On obtient :\n",
    "\n",
    "0.9868053089033629 {'n_estimators': 5750}    \n",
    "323.44272923469543 sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test finaux\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Par curiosité, on compare avec les learning rate et n_estimators choisis au premier test de XGBRegressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9865361034411432"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGBR1 = XGBRegressor( \n",
    "        n_estimators=4000,learning_rate=0.025,\n",
    "        max_depth=6, min_child_weight=1, \n",
    "        gamma = 0.0001, colsample_bytree=1, subsample=0.8714285714285714,\n",
    "        reg_alpha = 0.08071428571428571, reg_lambda= 0.15142857142857144\n",
    "    )\n",
    "XGBR1.fit(X_train, y_train)\n",
    "XGBR1.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9868053089033629"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGBR2 = XGBRegressor( \n",
    "        n_estimators = 5750,learning_rate = 0.015,\n",
    "        max_depth=6, min_child_weight=1, \n",
    "        gamma = 0.0001, colsample_bytree=1, subsample=0.8714285714285714,\n",
    "        reg_alpha = 0.08071428571428571, reg_lambda= 0.15142857142857144\n",
    "    )\n",
    "XGBR2.fit(X_train, y_train)\n",
    "XGBR2.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9868273520059674"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGBR3 = XGBRegressor( \n",
    "        n_estimators = 4000,learning_rate = 0.02,\n",
    "        max_depth=6, min_child_weight=1, \n",
    "        gamma = 0.0001, colsample_bytree=1, subsample=0.8714285714285714,\n",
    "        reg_alpha = 0.08071428571428571, reg_lambda= 0.15142857142857144\n",
    "    )\n",
    "XGBR3.fit(X_train, y_train)\n",
    "XGBR3.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On obtient un score meilleur pour XGBR3 donc on concervera ce modèle.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Préparation des données V2 - 2023/11/20 - SimpleImputer - Mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Import des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../../../data\"\n",
    "x_data = pd.read_csv(path + \"/Xtrain_hgcGIrA.csv\", sep=\",\")  # features\n",
    "y_data = pd.read_csv(\n",
    "    path + \"/Ytrain_yL5OjS4.csv\", sep=\",\", usecols=[1]\n",
    ")  # occupancy rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Préparation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = x_data.drop(\"date\", axis=1)  # on supprime la colonne date\n",
    "x_data = x_data.drop(\"way\", axis=1) #  on supprime la colonne way\n",
    "x_data[\"hour\"] = x_data[\"hour\"].apply(\n",
    "    lambda x: np.nan if type(x) == float else int(x[:2])\n",
    ") # on remplace les heures par des entiers en conservant les NaNs\n",
    "\n",
    "# on tranforme les identifiants de gare en entiers\n",
    "x_data[\"station\"] = x_data[\"station\"].astype(\"category\")\n",
    "cat_columns = x_data.select_dtypes([\"category\"]).columns\n",
    "x_data[cat_columns] = x_data[cat_columns].apply(lambda x: x.cat.codes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Remplacement des NaN par la moyenne de la colonne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on cherche à remplacer les valeurs NaN par une moyenne, \n",
    "# et on veut ajouter une colonne de features qui indique si a valeur était manquante en premier lieu\n",
    "SIM = SimpleImputer(missing_values=np.nan, strategy='mean', add_indicator=True)\n",
    "new_x_data = SIM.fit_transform(x_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>station</th>\n",
       "      <th>hour</th>\n",
       "      <th>composition</th>\n",
       "      <th>p1q0</th>\n",
       "      <th>p2q0</th>\n",
       "      <th>p3q0</th>\n",
       "      <th>p0q1</th>\n",
       "      <th>p0q2</th>\n",
       "      <th>p0q3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.138</td>\n",
       "      <td>0.091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train  station  hour  composition  p1q0  p2q0  p3q0   p0q1   p0q2   p0q3\n",
       "0      1        3   6.0            2   NaN   NaN   NaN  0.201  0.138  0.091"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.        , 23.        ,  7.3830557 ,  2.        ,  0.23476916,\n",
       "        0.25139248,  0.31686684,  0.20720034,  0.22216716,  0.20984504,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_x_data[406] # les valeurs NaNs ont bien été remplies. 7 colonnes ont été ajoutées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['train', 'station', 'hour', 'composition', 'p1q0', 'p2q0', 'p3q0',\n",
       "       'p0q1', 'p0q2', 'p0q3', 'missingindicator_hour',\n",
       "       'missingindicator_p1q0', 'missingindicator_p2q0',\n",
       "       'missingindicator_p3q0', 'missingindicator_p0q1',\n",
       "       'missingindicator_p0q2', 'missingindicator_p0q3'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SIM.get_feature_names_out(SIM.feature_names_in_) \n",
    "# les 7 colonnes correspondent bien au missing_indicator pour les colonnes où nous avions des NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.        , 23.        ,  7.3830557 ,  2.        ,  0.23476916,\n",
       "        0.25139248,  0.31686684,  0.20720034,  0.22216716,  0.20984504,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_x_data[406]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On rencontre cependant un problème pour hour, qui est une variable qu'on peut considérer catégorielle, mais qui à cause des NaNs, est considérée comme un float. La moyenne crée donc des valeurs probématiques. On va donc utiliser un autre Simple Imputer exclusivement pour hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data_full = SIM.fit_transform(x_data[['train', 'station', 'composition', 'p1q0', 'p2q0', 'p3q0', 'p0q1', 'p0q2', 'p0q3']])\n",
    "# on utilise bien SIM pour les autres variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 3.        , 2.        , 0.23476916, 0.25139248,\n",
       "       0.31686684, 0.201     , 0.138     , 0.091     , 1.        ,\n",
       "       1.        , 1.        , 0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data_full[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['train', 'station', 'composition', 'p1q0', 'p2q0', 'p3q0', 'p0q1',\n",
       "       'p0q2', 'p0q3', 'missingindicator_p1q0', 'missingindicator_p2q0',\n",
       "       'missingindicator_p3q0', 'missingindicator_p0q1',\n",
       "       'missingindicator_p0q2', 'missingindicator_p0q3'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SIM.get_feature_names_out(SIM.feature_names_in_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.        , 23.        ,  2.        ,  0.23476916,  0.25139248,\n",
       "        0.31686684,  0.20720034,  0.22216716,  0.20984504,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        7.        ,  1.        ])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SIMF = SimpleImputer(missing_values=np.nan, strategy='most_frequent', add_indicator=True)\n",
    "x_data_full = np.append(x_data_full, SIMF.fit_transform(x_data['hour'].to_numpy().reshape(-1, 1)), axis = 1)\n",
    "x_data_full[406]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 3.        , 2.        , 0.23476916, 0.25139248,\n",
       "       0.31686684, 0.201     , 0.138     , 0.091     , 1.        ,\n",
       "       1.        , 1.        , 0.        , 0.        , 0.        ,\n",
       "       6.        , 0.        ])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data_full[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'heure et sa colonne missing indicator son maintenant à la fin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Création d'un dataset de test et de validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    x_data_full, y_data.values, train_size=0.8\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoostREGRESSOR - 2023/11/20 - Préparation des données V2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Test sans jouer sur les paramètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9869137961334914"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "XGBR = XGBRegressor()\n",
    "XGBR.fit(X_train, y_train)\n",
    "XGBR.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Choix de n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9876457285653106 {'n_estimators': 875}\n",
      "60.46472883224487 sec\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from time import time\n",
    "\n",
    "start = time()\n",
    "\n",
    "my_kfold = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "n_estimators = [800,825,850,875,900,925,950]\n",
    "tuned_parameters = {\"n_estimators\": n_estimators}\n",
    "\n",
    "XGBR_params = GridSearchCV(\n",
    "    XGBRegressor(learning_rate=0.1), tuned_parameters, cv=my_kfold, n_jobs=-1\n",
    ")\n",
    "\n",
    "XGBR_params.fit(X_train, y_train)\n",
    "print(XGBR_params.score(X_test, y_test), XGBR_params.best_params_)\n",
    "print(str(time() - start) + \" sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Premier test avec\n",
    "\n",
    "- n_estimators = [100, 300, 500, 1000, 2000]\n",
    "\n",
    "On obtient :\n",
    "\n",
    "0.987631585074734 {'n_estimators': 1000}    \n",
    "49.5891170501709 sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deuxième test avec\n",
    "\n",
    "- n_estimators = [800,900, 1000, 1100, 1200,1500,1700, 2000]\n",
    "\n",
    "On obtient :\n",
    "\n",
    "0.9876367789297232 {'n_estimators': 900}    \n",
    "86.77404356002808 sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Troisième test avec\n",
    "\n",
    "- n_estimators = [800,850,900,950,1000,1050,1100,1150,1200]\n",
    "\n",
    "On obtient :\n",
    "\n",
    "0.9876386771444841 {'n_estimators': 850}    \n",
    "73.95417332649231 sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quatrième test avec\n",
    "\n",
    "- n_estimators = [800,825,850,875,900,925,950]\n",
    "\n",
    "On obtient :\n",
    "\n",
    "0.9876457285653106 {'n_estimators': 875}\n",
    "60.46472883224487 sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On s'arrête là pour l'instant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- choix de max_depth et min_child_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9875100229787886 {'max_depth': 8, 'min_child_weight': 5}\n",
      "1796.5100202560425 sec\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "\n",
    "my_kfold = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "max_depth = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, None]\n",
    "min_child_weight = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, None]\n",
    "\n",
    "tuned_parameters = {\n",
    "    \"max_depth\": max_depth,\n",
    "    \"min_child_weight\": min_child_weight,\n",
    "}\n",
    "\n",
    "XGBR_params = GridSearchCV(\n",
    "    XGBRegressor(n_estimators=875, learning_rate=0.1),\n",
    "    tuned_parameters,\n",
    "    cv=my_kfold,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "XGBR_params.fit(X_train, y_train)\n",
    "print(XGBR_params.score(X_test, y_test), XGBR_params.best_params_)\n",
    "print(str(time() - start) + \" sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Premier test avec :\n",
    "\n",
    "- max_depth = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
    "- min_child_weight = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
    "\n",
    "On obtient :\n",
    "0.9875100229787886 {'max_depth': 8, 'min_child_weight': 5}\n",
    "1796.5100202560425 sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Choix de gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9874671853255977 {'gamma': 1e-05}\n",
      "160.78628015518188 sec\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "\n",
    "my_kfold = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "gamma = np.linspace(0.00001,0.0011,15)\n",
    "\n",
    "tuned_parameters = {\"gamma\": gamma}\n",
    "\n",
    "XGBR_params = GridSearchCV(\n",
    "    XGBRegressor(\n",
    "        n_estimators=875, learning_rate=0.1, max_depth=8, min_child_weight=5\n",
    "    ),\n",
    "    tuned_parameters,\n",
    "    cv=my_kfold,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "XGBR_params.fit(X_train, y_train)\n",
    "print(XGBR_params.score(X_test, y_test), XGBR_params.best_params_)\n",
    "print(str(time() - start) + \" sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Premier test avec :\n",
    "\n",
    "- gamma = [0.1,0.5,1,5,10,30,50,100]\n",
    "\n",
    "On obtient :\n",
    "0.9778057482492879 {'gamma': 0.1}\n",
    "80.03496360778809 sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deuxième test avec\n",
    "\n",
    "- gamma = np.linspace(0.01,1.1,15)\n",
    "\n",
    "On obtient :\n",
    "\n",
    "0.9850280320319525 {'gamma': 0.01}\n",
    "140.01156759262085 sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Troisième test avec\n",
    "\n",
    "- gamma = np.linspace(0.001,0.11,15)\n",
    "\n",
    "On obtient :\n",
    "\n",
    "0.9872425524482036 {'gamma': 0.001}\n",
    "136.6466999053955 sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quatrième test avec\n",
    "\n",
    "- gamma = np.linspace(0.0001,0.011,15)\n",
    "\n",
    "On obtient :\n",
    "\n",
    "0.9874916840730203 {'gamma': 0.0001}\n",
    "162.4254322052002 sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cinquième test avec\n",
    "\n",
    "- gamma = np.linspace(0.00001,0.0011,15)\n",
    "\n",
    "On obtient :\n",
    "\n",
    "0.9874671853255977 {'gamma': 1e-05}\n",
    "160.78628015518188 sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le score ayant légèrement baissé, on prendra gamma = 0.0001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- choix de subsample et colsample_bytree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9874694820852845 {'colsample_bytree': 1.0, 'subsample': 0.9555555555555555}\n",
      "926.539966583252 sec\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "\n",
    "my_kfold = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "subsample = np.linspace(0.8,1,10)\n",
    "colsample_bytree = np.linspace(0.8,1,10)\n",
    "\n",
    "tuned_parameters = {\"subsample\": subsample, \"colsample_bytree\": colsample_bytree}\n",
    "\n",
    "XGBR_params = GridSearchCV(\n",
    "    XGBRegressor(\n",
    "        n_estimators=875, learning_rate=0.1, max_depth=8, min_child_weight=5, gamma = 0.0001\n",
    "    ),\n",
    "    tuned_parameters,\n",
    "    cv=my_kfold,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "XGBR_params.fit(X_train, y_train)\n",
    "print(XGBR_params.score(X_test, y_test), XGBR_params.best_params_)\n",
    "print(str(time() - start) + \" sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Premier test avec :\n",
    "\n",
    "- subsample = np.linspace(0.1,1,10)\n",
    "- colsample_bytree = np.linspace(0.1,1,10)\n",
    "\n",
    "On obtient :\n",
    "0.9874820676563881 {'colsample_bytree': 1.0, 'subsample': 0.9}\n",
    "578.6458947658539 sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deuxième test avec :\n",
    "\n",
    "- subsample = np.linspace(0.5,1,10)\n",
    "- colsample_bytree = np.linspace(0.5,1,10)\n",
    "\n",
    "On obtient :\n",
    "0.9873701809144972 {'colsample_bytree': 0.8333333333333333, 'subsample': 0.8888888888888888}\n",
    "766.0954196453094 sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Troisième test avec :\n",
    "\n",
    "- subsample = np.linspace(0.7,1,10)\n",
    "- colsample_bytree = np.linspace(0.7,1,10)\n",
    "\n",
    "On obtient :\n",
    "0.9877211237215808 {'colsample_bytree': 1.0, 'subsample': 0.8666666666666667}\n",
    "881.7824146747589 sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quatrième test avec :\n",
    "\n",
    "- subsample = np.linspace(0.8,1,10)\n",
    "- colsample_bytree = np.linspace(0.8,1,10)\n",
    "\n",
    "On obtient :\n",
    "0.9874694820852845 {'colsample_bytree': 1.0, 'subsample': 0.9555555555555555}\n",
    "926.539966583252 sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On décide de garder le troisième test : colsample_bytree = 1, subsample = 0.8666666666666667"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- choix de reg_alpha et reg_lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9882135749094555 {'reg_alpha': 0.13333333333333333, 'reg_lambda': 0.8222222222222222}\n",
      "967.8804669380188 sec\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "\n",
    "my_kfold = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "reg_alpha = np.linspace(0.05,0.3,10)\n",
    "reg_lambda = np.linspace(0.6,1,10)\n",
    "\n",
    "tuned_parameters = {\"reg_alpha\": reg_alpha, \"reg_lambda\": reg_lambda}\n",
    "\n",
    "XGBR_params = GridSearchCV(\n",
    "    XGBRegressor(\n",
    "        n_estimators=875, learning_rate=0.1, max_depth=8, min_child_weight=5, gamma = 0.0001, colsample_bytree=1, subsample=0.8666666666666667\n",
    "    ),\n",
    "    tuned_parameters,\n",
    "    cv=my_kfold,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "XGBR_params.fit(X_train, y_train)\n",
    "print(XGBR_params.score(X_test, y_test), XGBR_params.best_params_)\n",
    "print(str(time() - start) + \" sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Premier test avec\n",
    "- reg_alpha = [0.1,1,5,10,30,50,100]\n",
    "- reg_lambda = [0.1,1,5,10,30,50,100]\n",
    "\n",
    "On obtient :\n",
    "0.9882620721116913 {'reg_alpha': 0.1, 'reg_lambda': 1}\n",
    "219.1620478630066 sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deuxième test avec\n",
    "\n",
    "- reg_alpha = np.linspace(0.01,1,10)\n",
    "- reg_lambda = np.linspace(0.01,1,10)\n",
    "\n",
    "On obtient :\n",
    "\n",
    "0.9882449355818865 {'reg_alpha': 0.12, 'reg_lambda': 1.0}\n",
    "1016.8563673496246 sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Troisième test avec\n",
    "\n",
    "- reg_alpha = np.linspace(0.01,0.7,10)\n",
    "- reg_lambda = np.linspace(0.5,1,10)\n",
    "\n",
    "On obtient :\n",
    "\n",
    "0.9879991356922498 {'reg_alpha': 0.16333333333333333, 'reg_lambda': 0.8888888888888888}\n",
    "1026.3961491584778 sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quatrième test avec\n",
    "\n",
    "- reg_alpha = np.linspace(0.05,0.3,10)\n",
    "- reg_lambda = np.linspace(0.6,1,10)\n",
    "\n",
    "On obtient :\n",
    "\n",
    "0.9882135749094555 {'reg_alpha': 0.13333333333333333, 'reg_lambda': 0.8222222222222222}\n",
    "967.8804669380188 sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On garde le quatrième test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Diminution du learning rate et adaptation de n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9890216139609457 {'learning_rate': 0.025555555555555554, 'n_estimators': 2300}\n",
      "1798.641760110855 sec\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "\n",
    "my_kfold = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "n_estimators = np.arange(2000,3000,150)\n",
    "learning_rate = np.linspace(0.02,0.03,10)\n",
    "tuned_parameters = {\"n_estimators\": n_estimators, 'learning_rate': learning_rate}\n",
    "\n",
    "XGBR_params = GridSearchCV(\n",
    "    XGBRegressor( \n",
    "        max_depth=8, min_child_weight=5, gamma = 0.0001, colsample_bytree=1, subsample=0.8666666666666667,\n",
    "        reg_alpha= 0.13333333333333333, reg_lambda= 0.8222222222222222\n",
    "    ),\n",
    "    tuned_parameters,\n",
    "    cv=my_kfold,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "XGBR_params.fit(X_train, y_train) \n",
    "print(XGBR_params.score(X_test, y_test), XGBR_params.best_params_)\n",
    "print(str(time() - start) + \" sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Premier test avec\n",
    "\n",
    "- n_estimators = [875,1000, 2000,3000]\n",
    "- learning_rate = [0.02,0.05,0.08,0.1]\n",
    "\n",
    "On obtient :\n",
    "\n",
    "0.989016337558562 {'learning_rate': 0.02, 'n_estimators': 3000}\n",
    "331.3111243247986 sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deuxième test avec\n",
    "\n",
    "- n_estimators = np.arange(1000,5000,500)\n",
    "- learning_rate = np.linspace(0.01,0.05,10)\n",
    "\n",
    "On obtient :\n",
    "\n",
    "0.9890176223521759 {'learning_rate': 0.02333333333333333, 'n_estimators': 2500}\n",
    "2382.4112935066223 sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Troisième test avec\n",
    "\n",
    "- n_estimators = np.arange(1500,4000,250)\n",
    "- learning_rate = np.linspace(0.01,0.035,10)\n",
    "\n",
    "On obtient :\n",
    "\n",
    "0.989030871254338 {'learning_rate': 0.02388888888888889, 'n_estimators': 2250}\n",
    "2727.478348970413 sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quatrième test avec\n",
    "- n_estimators = np.arange(1500,3000,150)\n",
    "- learning_rate = np.linspace(0.015,0.03,10)\n",
    "\n",
    "On obtient\n",
    "\n",
    "0.9891347744501855 {'learning_rate': 0.024999999999999998, 'n_estimators': 2250}\n",
    "2188.679739713669 sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quatrième test avec\n",
    "- n_estimators = np.arange(2000,3000,150)\n",
    "- learning_rate = np.linspace(0.02,0.03,10)\n",
    "\n",
    "On obtient\n",
    "0.9890216139609457 {'learning_rate': 0.025555555555555554, 'n_estimators': 2300}    \n",
    "1798.641760110855 sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On garde le troisième test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Préparation des données V3 - 2023/11/22 - KNNImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Import des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../../../data\"\n",
    "x_data = pd.read_csv(path + \"/Xtrain_hgcGIrA.csv\", sep=\",\")  # features\n",
    "y_data = pd.read_csv(\n",
    "    path + \"/Ytrain_yL5OjS4.csv\", sep=\",\", usecols=[1]\n",
    ")  # occupancy rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Préparation des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On décide de garder la première stratégie : mettre des zéros à la place des heures NaNs. Pour les pxqx vides, on utilisera par contre bien les KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = x_data.drop(\"date\", axis=1)  # on supprime la colonne date\n",
    "x_data = x_data.drop(\"way\", axis=1) #  on supprime la colonne way\n",
    "x_data[\"hour\"] = x_data[\"hour\"].apply(\n",
    " lambda x: 0 if type(x) == float else int(x[:2])\n",
    ") # on remplace les heures par des entiers en conservant les NaNs\n",
    "\n",
    "# on tranforme les identifiants de gare en entiers\n",
    "x_data[\"station\"] = x_data[\"station\"].astype(\"category\")\n",
    "cat_columns = x_data.select_dtypes([\"category\"]).columns\n",
    "x_data[cat_columns] = x_data[cat_columns].apply(lambda x: x.cat.codes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Remplacement des NaN par KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "KNNI = KNNImputer(missing_values=np.nan, add_indicator=True)\n",
    "x_data_full = KNNI.fit_transform(x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>station</th>\n",
       "      <th>hour</th>\n",
       "      <th>composition</th>\n",
       "      <th>p1q0</th>\n",
       "      <th>p2q0</th>\n",
       "      <th>p3q0</th>\n",
       "      <th>p0q1</th>\n",
       "      <th>p0q2</th>\n",
       "      <th>p0q3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.138</td>\n",
       "      <td>0.091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train  station  hour  composition  p1q0  p2q0  p3q0   p0q1   p0q2   p0q3\n",
       "0      1        3     6            2   NaN   NaN   NaN  0.201  0.138  0.091"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 3.        , 6.        , 2.        , 0.2286    ,\n",
       "       0.25389724, 0.29123332, 0.201     , 0.138     , 0.091     ,\n",
       "       1.        , 1.        , 1.        , 0.        , 0.        ,\n",
       "       0.        ])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data_full[0] # les valeurs NaNs ont bien été remplies. 7 colonnes ont été ajoutées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['train', 'station', 'hour', 'composition', 'p1q0', 'p2q0', 'p3q0',\n",
       "       'p0q1', 'p0q2', 'p0q3', 'missingindicator_p1q0',\n",
       "       'missingindicator_p2q0', 'missingindicator_p3q0',\n",
       "       'missingindicator_p0q1', 'missingindicator_p0q2',\n",
       "       'missingindicator_p0q3'], dtype=object)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNNI.get_feature_names_out(KNNI.feature_names_in_) \n",
    "# les 7 colonnes correspondent bien au missing_indicator pour les colonnes où nous avions des NaNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Création d'un dataset de test et de validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    x_data_full, y_data.values, train_size=0.8\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoostREGRESSOR - 2023/11/22 - Préparation des données V3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Test sans jouer sur les paramètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9866072699818789"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "XGBR = XGBRegressor()\n",
    "XGBR.fit(X_train, y_train)\n",
    "XGBR.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- choix de n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9886325473238434 {'n_estimators': 930}\n",
      "114.22175073623657 sec\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from time import time\n",
    "\n",
    "start = time()\n",
    "\n",
    "my_kfold = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "n_estimators = [850,860,870,880,890,900,910,920,930,940,950,960,970,980,990,1000]\n",
    "tuned_parameters = {\"n_estimators\": n_estimators}\n",
    "\n",
    "XGBR_params = GridSearchCV(\n",
    "    XGBRegressor(learning_rate=0.1), tuned_parameters, cv=my_kfold, n_jobs=-1\n",
    ")\n",
    "\n",
    "XGBR_params.fit(X_train, y_train)\n",
    "print(XGBR_params.score(X_test, y_test), XGBR_params.best_params_)\n",
    "print(str(time() - start) + \" sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Premier test avec\n",
    "\n",
    "- n_estimators = [100, 300, 500, 1000, 2000]\n",
    "\n",
    "On obtient :\n",
    "\n",
    "0.9886483994296702 {'n_estimators': 1000}\n",
    "42.81796193122864 sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deuxième test avec\n",
    "\n",
    "- n_estimators = [800,850,900,950,1000,1050,1100,1150,1200,1500]\n",
    "\n",
    "On obtient :\n",
    "\n",
    "0.9886360824954366 {'n_estimators': 900}\n",
    "81.56852078437805 sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Troisième test avec\n",
    "\n",
    "- n_estimators = [850,860,870,880,890,900,910,920,930,940,950,960,970,980,990,1000]\n",
    "\n",
    "On obtient :\n",
    "\n",
    "0.9886325473238434 {'n_estimators': 930}\n",
    "114.22175073623657 sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- choix de max_depth et min_child_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.988217001877991 {'max_depth': 6, 'min_child_weight': 4.333333333333333}\n",
      "238.46584463119507 sec\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "\n",
    "my_kfold = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "max_depth = np.arange(4,8,1)\n",
    "min_child_weight = np.linspace(3,6,10)\n",
    "\n",
    "tuned_parameters = {\n",
    "    \"max_depth\": max_depth,\n",
    "    \"min_child_weight\": min_child_weight,\n",
    "}\n",
    "\n",
    "XGBR_params = GridSearchCV(\n",
    "    XGBRegressor(n_estimators=930, learning_rate=0.1),\n",
    "    tuned_parameters,\n",
    "    cv=my_kfold,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "XGBR_params.fit(X_train, y_train)\n",
    "print(XGBR_params.score(X_test, y_test), XGBR_params.best_params_)\n",
    "print(str(time() - start) + \" sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Premier test avec \n",
    "\n",
    "- max_depth = np.arange(1,15,1)\n",
    "- min_child_weight = np.arange(1,15,1)\n",
    "\n",
    "On obtient\n",
    "0.988217001877991 {'max_depth': 6, 'min_child_weight': 5}\n",
    "1339.3490736484528 sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deuxième test avec \n",
    "\n",
    "- max_depth = np.arange(1,10,1)\n",
    "- min_child_weight = np.linspace(1,10,15)\n",
    "\n",
    "On obtient\n",
    "0.988217001877991 {'max_depth': 6, 'min_child_weight': 4.214285714285714}\n",
    "750.9402289390564 sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Troisième test avec \n",
    "\n",
    "- max_depth = np.arange(4,8,1)\n",
    "- min_child_weight = np.linspace(3,6,10)\n",
    "\n",
    "On obtient\n",
    "0.988217001877991 {'max_depth': 6, 'min_child_weight': 4.333333333333333}\n",
    "238.46584463119507 sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le résultat ne change pas du tout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- choix de gamma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9882517157839599 {'gamma': 8.53061224489796e-05}\n",
      "282.04319047927856 sec\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "\n",
    "my_kfold = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "gamma = np.linspace(0.00001,0.0001,50)\n",
    "\n",
    "tuned_parameters = {\"gamma\": gamma}\n",
    "\n",
    "XGBR_params = GridSearchCV(\n",
    "    XGBRegressor(\n",
    "        n_estimators=930, learning_rate=0.1, max_depth=6, min_child_weight=4.333333333333333\n",
    "    ),\n",
    "    tuned_parameters,\n",
    "    cv=my_kfold,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "XGBR_params.fit(X_train, y_train)\n",
    "print(XGBR_params.score(X_test, y_test), XGBR_params.best_params_)\n",
    "print(str(time() - start) + \" sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Premier test avec \n",
    "- gamma = np.linspace(0.1,1,15)\n",
    "On obtient\n",
    "0.9749181204994332 {'gamma': 0.1}\n",
    "105.45138382911682 sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deuxième test avec \n",
    "- gamma = np.linspace(0.01,0.1,15)\n",
    "On obtient\n",
    "0.9835233622305644 {'gamma': 0.01}\n",
    "92.13753747940063 sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Troisième test avec \n",
    "- gamma = np.linspace(0.001,0.01,15)\n",
    "On obtient\n",
    "0.9876352652279332 {'gamma': 0.001}\n",
    "102.16498756408691 sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quatrième test avec \n",
    "- gamma = np.linspace(0.0001,0.001,15)\n",
    "On obtient\n",
    "0.9881168961617299 {'gamma': 0.0001}\n",
    "96.87253713607788 sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cinquième test avec \n",
    "- gamma = np.linspace(0.00001,0.0001,15)\n",
    "On obtient\n",
    "0.9880947378321867 {'gamma': 7.428571428571429e-05}\n",
    "99.55928111076355 sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sixième test avec \n",
    "- gamma = np.linspace(0.00001,0.0001,50)\n",
    "On obtient\n",
    "0.9882517157839599 {'gamma': 8.53061224489796e-05}\n",
    "282.04319047927856 sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- choix de subsample et colsample_bytree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9882517157839599 {'colsample_bytree': 1.0, 'subsample': 1.0}\n",
      "595.0831518173218 sec\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "\n",
    "my_kfold = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "subsample = np.linspace(0.5,1,10)\n",
    "colsample_bytree = np.linspace(0.5,1,10)\n",
    "\n",
    "tuned_parameters = {\"subsample\": subsample, \"colsample_bytree\": colsample_bytree}\n",
    "\n",
    "XGBR_params = GridSearchCV(\n",
    "    XGBRegressor(\n",
    "        n_estimators=930, learning_rate=0.1, max_depth=6, min_child_weight=4.333333333333333, gamma= 8.53061224489796e-05\n",
    "    ),\n",
    "    tuned_parameters,\n",
    "    cv=my_kfold,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "XGBR_params.fit(X_train, y_train)\n",
    "print(XGBR_params.score(X_test, y_test), XGBR_params.best_params_)\n",
    "print(str(time() - start) + \" sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Premier test avec :\n",
    "- subsample = np.linspace(0.1,1,10)\n",
    "- colsample_bytree = np.linspace(0.1,1,10)\n",
    "On obtient\n",
    "0.9882517157839599 {'colsample_bytree': 1.0, 'subsample': 1.0}\n",
    "383.3048412799835 sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deuxième test avec :\n",
    "- subsample = np.linspace(0.5,1,10)\n",
    "- colsample_bytree = np.linspace(0.5,1,10)\n",
    "On obtient\n",
    "0.9882517157839599 {'colsample_bytree': 1.0, 'subsample': 1.0}\n",
    "595.0831518173218 sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- choix de reg_alpha et reg_lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9886270986331853 {'reg_alpha': 0.14444444444444443, 'reg_lambda': 0.052222222222222225}\n",
      "63.54713201522827 sec\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "\n",
    "my_kfold = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "reg_alpha = np.linspace(0.1,0.2,20)\n",
    "reg_lambda = np.linspace(0.04,0.1,20)\n",
    "\n",
    "tuned_parameters = {\"reg_alpha\": reg_alpha, \"reg_lambda\": reg_lambda}\n",
    "\n",
    "XGBR_params = GridSearchCV(\n",
    "    XGBRegressor(\n",
    "        n_estimators=930, learning_rate=0.1, max_depth=6, min_child_weight=4.333333333333333, gamma= 8.53061224489796e-05,\n",
    "        colsample_bytree=1, subsample=1\n",
    "    ),\n",
    "    tuned_parameters,\n",
    "    cv=my_kfold,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "XGBR_params.fit(X_train, y_train)\n",
    "print(XGBR_params.score(X_test, y_test), XGBR_params.best_params_)\n",
    "print(str(time() - start) + \" sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Premier test avec\n",
    "- reg_alpha = [0.1,1,5,10,30,50,100]\n",
    "- reg_lambda = [0.1,1,5,10,30,50,100]\n",
    "\n",
    "On obtient\n",
    "0.9885051436678425 {'reg_alpha': 0.1, 'reg_lambda': 10}\n",
    "129.20628786087036 sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deuxième test avec\n",
    "- reg_alpha = np.linspace(0.01,10,10)\n",
    "- reg_lambda = np.linspace(0.1,50,10)\n",
    "\n",
    "On obtient\n",
    "0.9881017231449334 {'reg_alpha': 0.01, 'reg_lambda': 16.733333333333334}\n",
    "244.0652163028717 sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Troisième test avec\n",
    "- reg_alpha = np.linspace(0.01,1,10)\n",
    "- reg_lambda = np.linspace(0.1,20,10)\n",
    "\n",
    "On obtient\n",
    "0.9886693138278095 {'reg_alpha': 0.23, 'reg_lambda': 0.1}\n",
    "416.92906308174133 sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quatrième test avec\n",
    "- reg_alpha = np.linspace(0.05,0.8,10)\n",
    "- reg_lambda = np.linspace(0.01,5,10)\n",
    "\n",
    "On obtient\n",
    "0.9884720588664335 {'reg_alpha': 0.13333333333333333, 'reg_lambda': 3.336666666666667}\n",
    "423.8156259059906 sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cinquième test avec\n",
    "- reg_alpha = np.linspace(0.1,0.5,10)\n",
    "- reg_lambda = np.linspace(0.01,1,10)\n",
    "\n",
    "On obtient\n",
    "0.9885652780109305 {'reg_alpha': 0.14444444444444446, 'reg_lambda': 0.12}\n",
    "476.68485736846924 sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sixième test avec\n",
    "- reg_alpha = np.linspace(0.1,0.3,10)\n",
    "- reg_lambda = np.linspace(0.01,0.2,10)\n",
    "\n",
    "On obtient\n",
    "0.9886270986331853 {'reg_alpha': 0.14444444444444443, 'reg_lambda': 0.052222222222222225}\n",
    "570.3046953678131 sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sixième test avec\n",
    "- reg_alpha = np.linspace(0.1,0.2,20)\n",
    "- reg_lambda = np.linspace(0.04,0.1,20)\n",
    "\n",
    "On obtient\n",
    "0.9886043134006149 {'reg_alpha': 0.15263157894736842, 'reg_lambda': 0.08105263157894738}\n",
    "2558.2963654994965 sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- diminution de learning_rate et adaptation de n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9885325947953947 {'learning_rate': 0.02, 'n_estimators': 3760}\n",
      "861.2512314319611 sec\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "\n",
    "my_kfold = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "n_estimators = np.arange(3700,4000,10)\n",
    "learning_rate = [0.02]\n",
    "tuned_parameters = {\"n_estimators\": n_estimators, 'learning_rate': learning_rate}\n",
    "\n",
    "XGBR_params = GridSearchCV(\n",
    "    XGBRegressor( \n",
    "        max_depth=6, min_child_weight=4.333333333333333, gamma= 8.53061224489796e-05,\n",
    "        colsample_bytree=1, subsample=1,\n",
    "        reg_alpha= 0.15263157894736842, reg_lambda= 0.08105263157894738\n",
    "    ),\n",
    "    tuned_parameters,\n",
    "    cv=my_kfold,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "XGBR_params.fit(X_train, y_train) \n",
    "print(XGBR_params.score(X_test, y_test), XGBR_params.best_params_)\n",
    "print(str(time() - start) + \" sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Premier test avec\n",
    "\n",
    "- n_estimators = np.arange(930,5000,500)\n",
    "- learning_rate = [0.02]\n",
    "\n",
    "On obtient :\n",
    "\n",
    "0.9885404675773862 {'learning_rate': 0.02, 'n_estimators': 3930}\n",
    "275.73846888542175 sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deuxième test avec\n",
    "\n",
    "- n_estimators = np.arange(3000,5000,200)\n",
    "- learning_rate = [0.02]\n",
    "\n",
    "On obtient :\n",
    "\n",
    "0.9885321172470223 {'learning_rate': 0.02, 'n_estimators': 3800}\n",
    "318.14975929260254 sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Troisième test avec\n",
    "\n",
    "- n_estimators = np.arange(3000,4000,50)\n",
    "- learning_rate = [0.02]\n",
    "\n",
    "On obtient :\n",
    "\n",
    "0.9885328509718507 {'learning_rate': 0.02, 'n_estimators': 3750}\n",
    "588.039425611496 sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quatrième test avec\n",
    "\n",
    "- n_estimators = np.arange(3700,4000,10)\n",
    "- learning_rate = [0.02]\n",
    "\n",
    "On obtient :\n",
    "\n",
    "0.9885325947953947 {'learning_rate': 0.02, 'n_estimators': 3760}\n",
    "861.2512314319611 sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On s'arrête au quatrième test."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "STASC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
