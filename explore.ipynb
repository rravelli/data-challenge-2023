{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats \n",
    "import numpy\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import et présentation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>train</th>\n",
       "      <th>way</th>\n",
       "      <th>station</th>\n",
       "      <th>hour</th>\n",
       "      <th>composition</th>\n",
       "      <th>p1q0</th>\n",
       "      <th>p2q0</th>\n",
       "      <th>p3q0</th>\n",
       "      <th>p0q1</th>\n",
       "      <th>p0q2</th>\n",
       "      <th>p0q3</th>\n",
       "      <th>p0q0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-07</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>AD</td>\n",
       "      <td>06:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.138</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-08</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>AD</td>\n",
       "      <td>06:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>AD</td>\n",
       "      <td>06:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.213</td>\n",
       "      <td>0.153</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>AD</td>\n",
       "      <td>06:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.213</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>AD</td>\n",
       "      <td>06:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31114</th>\n",
       "      <td>2019-05-13</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>BE</td>\n",
       "      <td>08:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.18860</td>\n",
       "      <td>0.157000</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31115</th>\n",
       "      <td>2019-05-14</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>BE</td>\n",
       "      <td>08:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>0.153</td>\n",
       "      <td>0.18040</td>\n",
       "      <td>0.191000</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.121</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31116</th>\n",
       "      <td>2019-05-15</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>BE</td>\n",
       "      <td>08:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>0.166</td>\n",
       "      <td>0.14900</td>\n",
       "      <td>0.168000</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.129</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31117</th>\n",
       "      <td>2019-03-21</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>BE</td>\n",
       "      <td>08:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.19300</td>\n",
       "      <td>0.162000</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.101</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31118</th>\n",
       "      <td>2019-01-30</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>BE</td>\n",
       "      <td>08:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.16928</td>\n",
       "      <td>0.187717</td>\n",
       "      <td>0.289</td>\n",
       "      <td>0.354</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.416</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31119 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             date  train  way station      hour  composition   p1q0     p2q0  \\\n",
       "0      2019-01-07      1    0      AD  06:00:00            2    NaN      NaN   \n",
       "1      2019-01-08      1    0      AD  06:00:00            2    NaN      NaN   \n",
       "2      2019-01-10      1    0      AD  06:00:00            2    NaN      NaN   \n",
       "3      2019-01-11      1    0      AD  06:00:00            2    NaN      NaN   \n",
       "4      2019-01-14      1    0      AD  06:00:00            2    NaN      NaN   \n",
       "...           ...    ...  ...     ...       ...          ...    ...      ...   \n",
       "31114  2019-05-13      9    0      BE  08:00:00            2  0.152  0.18860   \n",
       "31115  2019-05-14      9    0      BE  08:00:00            2  0.153  0.18040   \n",
       "31116  2019-05-15      9    0      BE  08:00:00            2  0.166  0.14900   \n",
       "31117  2019-03-21      9    0      BE  08:00:00            2  0.182  0.19300   \n",
       "31118  2019-01-30      9    0      BE  08:00:00            1  0.173  0.16928   \n",
       "\n",
       "           p3q0   p0q1   p0q2   p0q3   p0q0  \n",
       "0           NaN  0.201  0.138  0.091  0.216  \n",
       "1           NaN  0.204  0.152  0.106  0.216  \n",
       "2           NaN  0.213  0.153  0.111  0.227  \n",
       "3           NaN  0.213  0.152  0.108  0.229  \n",
       "4           NaN  0.210  0.147  0.096  0.225  \n",
       "...         ...    ...    ...    ...    ...  \n",
       "31114  0.157000  0.080  0.100    NaN  0.111  \n",
       "31115  0.191000  0.089  0.121    NaN  0.143  \n",
       "31116  0.168000  0.099  0.129    NaN  0.139  \n",
       "31117  0.162000  0.074  0.101    NaN  0.117  \n",
       "31118  0.187717  0.289  0.354    NaN  0.416  \n",
       "\n",
       "[31119 rows x 13 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = './data'\n",
    "x_data = pd.read_csv(path+'/Xtrain_hgcGIrA.csv', sep=',') # features\n",
    "y_data = pd.read_csv(path+'/Ytrain_yL5OjS4.csv', sep=',', usecols=[1]) # occupancy rate\n",
    "\n",
    "data = pd.merge(\n",
    "    x_data,\n",
    "    y_data,\n",
    "    how=\"inner\",\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    "    copy=True,\n",
    "    indicator=False,\n",
    "    validate=None,\n",
    ") # merged dataframe\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notre dataset d'entraînement comporte 31118 échantillons. Pour chaque ligne, on dispose des 12 features suivantes :\n",
    "1. La date du jour où le trajet a lieu\n",
    "2. Le numéro du train considéré de 1 à 55\n",
    "3. Le sens de parcours - 0 pour dire vers Paris / 1 pour dire vers depuis Paris\n",
    "4. L'identifiant de la gare où s'arrête le train\n",
    "5. L'heure à laquelle le train s'arrête à la gare\n",
    "6. Le nombre de rames du train (1 ou 2)\n",
    "7-9. p1q0, p2q0, p3q0 : respectivement le taux d'occupation du dernier train, avant-dernier et avant-avant-dernier train au même arrêt\n",
    "10-12. p0q1, p0q2, p0q3 : respectivement le taux d'occupation du même train au dernier arrêt, avant-dernier et avant-avant-dernier arrêt\n",
    "\n",
    "On dispose aussi d'une colonne cible p0q0 : le taux d'occupation du train courant à l'arrêt courant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 31118 entries, 1 to 31118\n",
      "Data columns (total 13 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   date         31118 non-null  object \n",
      " 1   train        31118 non-null  int64  \n",
      " 2   way          31118 non-null  int64  \n",
      " 3   station      31118 non-null  object \n",
      " 4   hour         27914 non-null  object \n",
      " 5   composition  31118 non-null  int64  \n",
      " 6   p1q0         29067 non-null  float64\n",
      " 7   p2q0         26974 non-null  float64\n",
      " 8   p3q0         24935 non-null  float64\n",
      " 9   p0q1         27916 non-null  float64\n",
      " 10  p0q2         24719 non-null  float64\n",
      " 11  p0q3         21526 non-null  float64\n",
      " 12  p0q0         31118 non-null  float64\n",
      "dtypes: float64(7), int64(3), object(3)\n",
      "memory usage: 3.3+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afin de pouvoir mieux étudier notre dataset, nous allons rectifier certains typages fait par pandas qui ne sont pas appropriés : en effet, train et way, même si ce sont bien des entiers, doivent être considérés comme des variables catégorielles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['train'] = data['train'].astype('category')\n",
    "data['way'] = data['way'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Étude des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gestion des NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date              0\n",
       "train             0\n",
       "way               0\n",
       "station           0\n",
       "hour           3204\n",
       "composition       0\n",
       "p1q0           2052\n",
       "p2q0           4145\n",
       "p3q0           6184\n",
       "p0q1           3202\n",
       "p0q2           6399\n",
       "p0q3           9592\n",
       "p0q0              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.isna(data).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>train</th>\n",
       "      <th>way</th>\n",
       "      <th>station</th>\n",
       "      <th>hour</th>\n",
       "      <th>composition</th>\n",
       "      <th>p1q0</th>\n",
       "      <th>p2q0</th>\n",
       "      <th>p3q0</th>\n",
       "      <th>p0q1</th>\n",
       "      <th>p0q2</th>\n",
       "      <th>p0q3</th>\n",
       "      <th>p0q0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>2019-01-07</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>AX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>2019-01-08</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>AX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>2019-01-10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>AX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>2019-01-11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>AX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>2019-01-14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>AX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30938</th>\n",
       "      <td>2019-05-13</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>AX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0840</td>\n",
       "      <td>0.110822</td>\n",
       "      <td>0.0970</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30939</th>\n",
       "      <td>2019-05-14</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>AX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0940</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.1190</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30940</th>\n",
       "      <td>2019-05-15</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>AX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0910</td>\n",
       "      <td>0.085000</td>\n",
       "      <td>0.1060</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30941</th>\n",
       "      <td>2019-03-21</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>AX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1070</td>\n",
       "      <td>0.107000</td>\n",
       "      <td>0.0950</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30942</th>\n",
       "      <td>2019-01-30</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>AX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1076</td>\n",
       "      <td>0.096760</td>\n",
       "      <td>0.1074</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.289</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3204 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             date train way station hour  composition    p1q0      p2q0  \\\n",
       "406    2019-01-07     1   0      AX  NaN            2     NaN       NaN   \n",
       "407    2019-01-08     1   0      AX  NaN            2     NaN       NaN   \n",
       "408    2019-01-10     1   0      AX  NaN            2     NaN       NaN   \n",
       "409    2019-01-11     1   0      AX  NaN            2     NaN       NaN   \n",
       "410    2019-01-14     1   0      AX  NaN            2     NaN       NaN   \n",
       "...           ...   ...  ..     ...  ...          ...     ...       ...   \n",
       "30938  2019-05-13     9   0      AX  NaN            2  0.0840  0.110822   \n",
       "30939  2019-05-14     9   0      AX  NaN            2  0.0940  0.100000   \n",
       "30940  2019-05-15     9   0      AX  NaN            2  0.0910  0.085000   \n",
       "30941  2019-03-21     9   0      AX  NaN            2  0.1070  0.107000   \n",
       "30942  2019-01-30     9   0      AX  NaN            1  0.1076  0.096760   \n",
       "\n",
       "         p3q0  p0q1  p0q2  p0q3   p0q0  \n",
       "406       NaN   NaN   NaN   NaN  0.045  \n",
       "407       NaN   NaN   NaN   NaN  0.044  \n",
       "408       NaN   NaN   NaN   NaN  0.061  \n",
       "409       NaN   NaN   NaN   NaN  0.042  \n",
       "410       NaN   NaN   NaN   NaN  0.043  \n",
       "...       ...   ...   ...   ...    ...  \n",
       "30938  0.0970   NaN   NaN   NaN  0.080  \n",
       "30939  0.1190   NaN   NaN   NaN  0.089  \n",
       "30940  0.1060   NaN   NaN   NaN  0.099  \n",
       "30941  0.0950   NaN   NaN   NaN  0.074  \n",
       "30942  0.1074   NaN   NaN   NaN  0.289  \n",
       "\n",
       "[3204 rows x 13 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[data['hour'].isna()] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une des spécificités de notre dataset est le nombre très important de valeurs manquantes. Les colonnes concernées sont hour, p1q0, p2q0, p3q0, p0q1, p0q2, et p0q3.\n",
    "La SNCF explique cela par le fait que les valeurs sont inexistantes à cause de la structure de leur grille horaire.\n",
    "\n",
    "Plusieurs algorithmes de Machine Learning n'autorise pas des datasets avec des valeurs manquantes. Il faut donc que nous trouvions un moyen de contourner ce problème."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Si on décide de supprimer toutes les lignes avec des valeurs NaN :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17666, 13)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_no_na = data.dropna()\n",
    "data_no_na.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21513, 11)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "other_data_no_na = data.drop(labels=['p0q3', \"p3q0\"], axis = 1)\n",
    "other_data_no_na = other_data_no_na.dropna()\n",
    "other_data_no_na.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si on choisit de supprimer toutes les lignes avec des valeurs NaN, on perd 43,23% des données de notre dataset. 17 666 reste un nombre important d'échantillons mais il faudrait mieux trouver un autre moyen car les lignes avec des données manquantes ont aussi des données non manquantes utiles.\n",
    "On peut aussi choisir de supprimer des colonnes, par exemple p0q3 et p3q0, qui sont les données les plus \"éloignées\" et qui ont un nombre important de NaN. Avec cela, on conserve 21 513 lignes ce qui correspond à 215 130 données contre 211 992 données pour la solution précédente.\n",
    "\n",
    "Il faudra cependant adapter la situation à l'algorithme choisi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Si on décide de ne pas supprimer les lignes avec des NaN :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supprimer les valeurs NaN de notre dataset conduit à beaucoup de pertes, celles-ci étant nombreuses. Une meilleure option serait de faire avec ces valeurs NaN, en adaptant les algorithmes utilisés par exemple : certains acceptent des datasets avec des NaN. Cela réduit cependant notre champ d'action.    \n",
    "Une autre possibilité est de compléter nos valeurs manquantes par régression linéaire, dans le cas où on dispose d'autres variables très corrélées.\n",
    "\n",
    "Source : https://larevueia.fr/4-methodes-pour-gerer-les-donnees-manquantes-en-machine-learning-avec-pandas/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statistiques chiffrés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>composition</th>\n",
       "      <th>p1q0</th>\n",
       "      <th>p2q0</th>\n",
       "      <th>p3q0</th>\n",
       "      <th>p0q1</th>\n",
       "      <th>p0q2</th>\n",
       "      <th>p0q3</th>\n",
       "      <th>p0q0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>31118.000000</td>\n",
       "      <td>29067.000000</td>\n",
       "      <td>26974.000000</td>\n",
       "      <td>24935.000000</td>\n",
       "      <td>27916.000000</td>\n",
       "      <td>24719.000000</td>\n",
       "      <td>21526.000000</td>\n",
       "      <td>31118.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.999647</td>\n",
       "      <td>0.234769</td>\n",
       "      <td>0.251392</td>\n",
       "      <td>0.316867</td>\n",
       "      <td>0.207201</td>\n",
       "      <td>0.222171</td>\n",
       "      <td>0.209851</td>\n",
       "      <td>0.248748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.018798</td>\n",
       "      <td>0.166153</td>\n",
       "      <td>0.143506</td>\n",
       "      <td>0.150974</td>\n",
       "      <td>0.134711</td>\n",
       "      <td>0.147603</td>\n",
       "      <td>0.144859</td>\n",
       "      <td>0.157366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.094000</td>\n",
       "      <td>0.136000</td>\n",
       "      <td>0.196000</td>\n",
       "      <td>0.099000</td>\n",
       "      <td>0.107000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.121000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.192000</td>\n",
       "      <td>0.230000</td>\n",
       "      <td>0.312000</td>\n",
       "      <td>0.181000</td>\n",
       "      <td>0.188000</td>\n",
       "      <td>0.172000</td>\n",
       "      <td>0.220000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.363000</td>\n",
       "      <td>0.354000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.294000</td>\n",
       "      <td>0.322000</td>\n",
       "      <td>0.292000</td>\n",
       "      <td>0.360000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.934000</td>\n",
       "      <td>0.937000</td>\n",
       "      <td>0.937000</td>\n",
       "      <td>0.969000</td>\n",
       "      <td>0.974000</td>\n",
       "      <td>0.974000</td>\n",
       "      <td>0.974000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        composition          p1q0          p2q0          p3q0          p0q1  \\\n",
       "count  31118.000000  29067.000000  26974.000000  24935.000000  27916.000000   \n",
       "mean       1.999647      0.234769      0.251392      0.316867      0.207201   \n",
       "std        0.018798      0.166153      0.143506      0.150974      0.134711   \n",
       "min        1.000000      0.000000      0.000000      0.000000      0.004000   \n",
       "25%        2.000000      0.094000      0.136000      0.196000      0.099000   \n",
       "50%        2.000000      0.192000      0.230000      0.312000      0.181000   \n",
       "75%        2.000000      0.363000      0.354000      0.420000      0.294000   \n",
       "max        2.000000      0.934000      0.937000      0.937000      0.969000   \n",
       "\n",
       "               p0q2          p0q3          p0q0  \n",
       "count  24719.000000  21526.000000  31118.000000  \n",
       "mean       0.222171      0.209851      0.248748  \n",
       "std        0.147603      0.144859      0.157366  \n",
       "min        0.004000      0.004000      0.000000  \n",
       "25%        0.107000      0.100000      0.121000  \n",
       "50%        0.188000      0.172000      0.220000  \n",
       "75%        0.322000      0.292000      0.360000  \n",
       "max        0.974000      0.974000      0.974000  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le tableau ci-dessus nous apprend notamment que :\n",
    "- La majorité des trains qui circulent sont des trains à deux rames\n",
    "- En moyenne, le taux d'occupation des trains tourne autour de 0,2/0,3. Des taux d'occupation de 0,9 sont très rares (75 pourcent des valeurs sont inférieures ou égales à 0,4 au maximum pour p3q0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "composition    2.000\n",
       "p1q0           0.192\n",
       "p2q0           0.230\n",
       "p3q0           0.312\n",
       "p0q1           0.181\n",
       "p0q2           0.188\n",
       "p0q3           0.172\n",
       "p0q0           0.220\n",
       "dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.median(numeric_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les médianes confirment nos conclusions précédentes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plots"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "STASC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
