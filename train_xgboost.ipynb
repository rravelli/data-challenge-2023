{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On choisit XGBoost car il accepte des datasets avec des valeurs manquantes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Préparation des données V1 - 2023/11/13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stratégie :    \n",
    "On remplace les heures par des floats, les identifiants de station par des entiers et on supprime la colonne 'date'.    \n",
    "(La suppression de la colonne 'way' a été oubliée)\n",
    "On a fait une division : 90% du dataset pour le train, 10% pour le test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Import des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './data'\n",
    "x_data = pd.read_csv(path+'/Xtrain_hgcGIrA.csv', sep=',') # features\n",
    "y_data = pd.read_csv(path+'/Ytrain_yL5OjS4.csv', sep=',', usecols=[1]) # occupancy rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mise en forme des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data=x_data.drop('date', axis=1) # on supprime la colonne date\n",
    "x_data[\"hour\"] = x_data[\"hour\"].apply(lambda x: int(x[:2]) if isinstance(x, str) else np.nan) # on transforme les strings des heures en float\n",
    "#on tranforme les identifiants de gare en entiers\n",
    "x_data[\"station\"] = x_data[\"station\"].astype('category')\n",
    "cat_columns = x_data.select_dtypes([\"category\"]).columns\n",
    "x_data[cat_columns] = x_data[cat_columns].apply(lambda x: x.cat.codes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Création d'un dataset de test et de validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_data.values,y_data.values,train_size=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoostREGRESSOR - 2023/11/13 - Préparation des données V1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On utilise le regresseur et pas le classifieur car on ne cherche pas la classe de p0q0 mais sa valeur précise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Import de XGBRegresseur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Test sans jouer sur les paramètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9872039534087059"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGBR = XGBRegressor()\n",
    "XGBR.fit(X_train, y_train)\n",
    "XGBR.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le score est assez bon, cependant, en jouant sur les paramètres, on va essayer de l'augmenter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Choix de learning_rate et n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9896284435980697 {'learning_rate': 0.05, 'n_estimators': 2000}\n",
      "155.02244329452515 sec\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from time import time\n",
    "\n",
    "start = time()\n",
    "\n",
    "my_kfold = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "n_estimators = [300, 500, 1000, 2000]\n",
    "learning_rate = [0.005, 0.01, 0.05, 0.1]\n",
    "\n",
    "tuned_parameters = {'n_estimators': n_estimators, 'learning_rate' : learning_rate}  \n",
    "\n",
    "XGBR_params = GridSearchCV(XGBRegressor(),\n",
    "                      tuned_parameters,\n",
    "                      cv=my_kfold,\n",
    "                      n_jobs=-1)\n",
    "\n",
    "XGBR_params.fit(X_train, y_train)\n",
    "print(XGBR_params.score(X_test, y_test), XGBR_params.best_params_)\n",
    "print(str(time() - start)+ \" sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Premier test avec \n",
    "- n_estimators = [300, 500, 1000, 2000]\n",
    "- learning_rate = [0.005, 0.01, 0.05, 0.1]\n",
    "\n",
    "On obtient : \n",
    "\n",
    "0.9896284435980697 {'learning_rate': 0.05, 'n_estimators': 2000}\n",
    "155.02244329452515 sec\n",
    "\n",
    "Le score obtenu est meilleur, mais on va essayer d'affiner ces résultats \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deuxième test avec :\n",
    "- n_estimators = [1000, 1500, 2000, 2500, 3000]\n",
    "- learning_rate = [0.01, 0.025, 0.05, 0.075, 0.1]\n",
    "\n",
    "On obtient :\n",
    "\n",
    "0.9895109476080269 {'learning_rate': 0.025, 'n_estimators': 3000}    \n",
    "427.96634221076965 sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Troisième test avec :\n",
    "- n_estimators = [2750, 3000, 3250, 3500]\n",
    "- learning_rate = [0.01, 0.025, 0.05, 0.075]\n",
    "\n",
    "On obtient :\n",
    "\n",
    "0.9895371733074723 {'learning_rate': 0.025, 'n_estimators': 3500}    \n",
    "564.882648229599 sec\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quatrième test avec : \n",
    "- n_estimators = [3000, 3250, 3500, 3750, 4000]\n",
    "- learning_rate = [0.01, 0.025, 0.05]\n",
    "\n",
    "On obtient :\n",
    "\n",
    "0.9895812224115239 {'learning_rate': 0.025, 'n_estimators': 4000}\n",
    "463.68704533576965 sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On choisit de s'arrêter là pour voir l'impact des autres paramètres sur le score. Les deux meilleurs couples sont, pour n_estimators et learning_rate (0.05,2000) et (0.025,4000). On utilisera le pre;ier pour optimiser les autres paramètres, puis, on verra quel couple permet d'avoir le meilleur score final. Dans l'éventuel cas où ce serait (0.025,4000), on pourra essayer d'augmenter encore n_estimators."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- choix de max_depth et gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9892712110007462 {'max_depth': 7, 'min_child_weight': 8}\n",
      "456.5879855155945 sec\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "\n",
    "my_kfold = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "max_depth = [5,6,7,8,9]\n",
    "min_child_weight = [5,6,7,8,9]\n",
    "\n",
    "tuned_parameters = {'max_depth': max_depth, 'min_child_weight' : min_child_weight}  \n",
    "\n",
    "XGBR_params = GridSearchCV(XGBRegressor(n_estimators=2000, learning_rate = 0.05),\n",
    "                      tuned_parameters,\n",
    "                      cv=my_kfold,\n",
    "                      n_jobs=-1)\n",
    "\n",
    "XGBR_params.fit(X_train, y_train)\n",
    "print(XGBR_params.score(X_test, y_test), XGBR_params.best_params_)\n",
    "print(str(time() - start)+ \" sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Premier test avec \n",
    "- max_depth = [1, 10, 100]\n",
    "- min_child_weight = [1, 10, 100]\n",
    "\n",
    "On obtient : \n",
    "\n",
    "0.988740513845699 {'max_depth': 10, 'min_child_weight': 10}    \n",
    "442.56765842437744 sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deuxième test avec \n",
    "- max_depth = [5, 10, 25, 50]\n",
    "- min_child_weight = [5, 10, 25, 50]\n",
    "\n",
    "On obtient : \n",
    "\n",
    "0.989310996503391 {'max_depth': 5, 'min_child_weight': 5}    \n",
    "659.9102652072906 sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Troisième test avec \n",
    "- max_depth = [3,5,7,10,15]\n",
    "- min_child_weight = [3,5,7,10,15]\n",
    "\n",
    "On obtient : \n",
    "\n",
    "0.9892469163908968 {'max_depth': 7, 'min_child_weight': 7}\n",
    "456.729660987854 sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quatrième test avec : \n",
    "- max_depth = [5,6,7,8,9]\n",
    "- min_child_weight = [5,6,7,8,9]\n",
    "\n",
    "On obtient : \n",
    "\n",
    "0.9892712110007462 {'max_depth': 7, 'min_child_weight': 8}    \n",
    "456.5879855155945 sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On choisit max_depth = 7 et min_child_weight = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- choix de reg_alpha et reg_lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9892045975248401 {'reg_alpha': 0.15, 'reg_lambda': 0.21}\n",
      "327.5475251674652 sec\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "\n",
    "my_kfold = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "reg_alpha = [0.3, 0.14, 0.15, 0.16, 0.17]\n",
    "reg_lambda = [0.18, 0.19, 0.2, 0.21, 0.22]\n",
    "\n",
    "tuned_parameters = {'reg_alpha': reg_alpha, 'reg_lambda' : reg_lambda}  \n",
    "\n",
    "XGBR_params = GridSearchCV(XGBRegressor(n_estimators=2000, learning_rate = 0.05, max_depth = 7, min_child_weight = 8),\n",
    "                      tuned_parameters,\n",
    "                      cv=my_kfold,\n",
    "                      n_jobs=-1)\n",
    "\n",
    "XGBR_params.fit(X_train, y_train)\n",
    "print(XGBR_params.score(X_test, y_test), XGBR_params.best_params_)\n",
    "print(str(time() - start)+ \" sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Premier test avec \n",
    "- reg_alpha = [0.1, 1, 10, 100]\n",
    "- reg_lambda = [0.1, 1, 10, 100]\n",
    "\n",
    "On obtient : \n",
    "\n",
    "0.9891920131398381 {'reg_alpha': 0.1, 'reg_lambda': 0.1}    \n",
    "143.50136017799377 sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deuxième test avec \n",
    "- reg_alpha = [0.05 , 0.1, 0.15, 0.2]\n",
    "- reg_lambda = [0.05 , 0.1, 0.15, 0.2]\n",
    "\n",
    "On obtient : \n",
    "\n",
    "0.9891699132652103 {'reg_alpha': 0.15, 'reg_lambda': 0.2}    \n",
    "241.633647441864 sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le résultat est inférieur à partir du 10-millième."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Troisième test avec \n",
    "- reg_alpha = [0.1, 0.125, 0.15, 0.175]\n",
    "- reg_lambda = [0.08 , 0.12, 0.16, 0.2, 0.25]\n",
    "\n",
    "On obtient : \n",
    "\n",
    "0.9891699132652103 {'reg_alpha': 0.15, 'reg_lambda': 0.2}\n",
    "296.16087889671326 sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On choisit de creuser autour de 0.15 et 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quatrième test avec \n",
    "- reg_alpha = [0.3, 0.14, 0.15, 0.16, 0.17]\n",
    "- reg_lambda = [0.18, 0.19, 0.2, 0.21, 0.22]\n",
    "\n",
    "On obtient : \n",
    "\n",
    "0.9892045975248401 {'reg_alpha': 0.15, 'reg_lambda': 0.21}    \n",
    "327.5475251674652 sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test finaux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9892045975248401"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGBR1 = XGBRegressor(n_estimators=2000, learning_rate = 0.05, max_depth = 7, min_child_weight = 8, reg_alpha = 0.15, reg_lambda = 0.21)\n",
    "XGBR1.fit(X_train, y_train)\n",
    "XGBR1.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9892679703760023"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGBR2 = XGBRegressor(n_estimators=4000, learning_rate = 0.025, max_depth = 7, min_child_weight = 8, reg_alpha = 0.15, reg_lambda = 0.21)\n",
    "XGBR2.fit(X_train, y_train)\n",
    "XGBR2.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On explore un peu les résultats si on augment n_estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9892679703760023"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGBR2_1 = XGBRegressor(n_estimators=5000, learning_rate = 0.025, max_depth = 7, min_child_weight = 8, reg_alpha = 0.15, reg_lambda = 0.21)\n",
    "XGBR2_1.fit(X_train, y_train)\n",
    "XGBR2_1.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le score n'évolue pas du tout, on choisit de garder XGBR2."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "STASC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
